batches*(10x300x64) is (MIC channels, sequence length (number of STFT frames), mel-bands)

n_features = n_channels



TO DOO:::

1)Parameter sharing
SED + DOA separate

2)Data augmentation

3)LSTM ->>in progress DONE 

2/3/2022

Check resnet18 dimension problem
Write eidiko thema report
Copied cudnn64_7.dll on c:/program files/nvidia/cuda/bin->>>cuda recognised on dummy program


3/3/2022
Check Park's report SELF-ATTENTION MECHANISM FOR SOUND EVENT LOCALIZATION AND DETECTION
for self-attention

AAAAnnyyywaysss

IDEA:combined Conformer and ResNet--->>>>eNSEMBLE-LIKE SYSTEM??
replace the GRU block
with a time-frequency RNN (TFRNN) block (read Shimada's paper)

Read A.Politis report(DCASE baseline report):
 The DOA methods in literature
can be broadly categorized into parametric- and deep neural
network (DNN)-based approaches(SEE https://www.aane.in/research/computational-audio-scene-analysis-casa/sound-event-localization-and-tracking
FOR MORE)

DNN based methods for DOA for static sources better than parametric

 microphone arrays with
full azimuth and elevation coverage, such as spherical microphone arrays, rely strongly on the directionality of the sensors
to capture spatial information, this reflects mainly in the magnitude differences between channels. Motivated by this fact
we proposed to use both the magnitude and phase component
of the spectrogram as input features in [25]. Thus making the
DOA estimation method [25] generic to array configuration
by avoiding method-specific feature extractions

 The problem is further extended for the polyphonic
SELD task if the SED and DOA estimation are done separately, resulting in the data association problem between
the recognized sound events and the estimated DOAs [13].
One solution to the data association problem is to jointly
predict the SED and DOA. In this regard, to the best of
the authorsâ€™ knowledge, [20] is the only DNN-based method
which performs SELD. Other works combining SED and
parametric DOA estimation include [

e number of existing SELD methods is limited [6, 13, 20, 52, 53], with only one published DNN-based
approach

RWTAW PPOTAMIANO GIA TO EXTRACTION (MEL BANDS, FFT .... NUMBER OF BINS?? )


5/02/2022

TO DO:: MSE loss instead of ACCDOA

Lowered batch size to get rid of OEM in GPU
Got new error (yay)::
Internal: Blas GEMM launch failed

->>import keras.backend.tensorflow_backend as KTF
import tensorflow as tf
config = tf.ConfigProto()
config.gpu_options.allow_growth=True   
sess = tf.Session(config=config)

KTF.set_session(sess)

NOT WORKING
TRY IT ON UBUNTU WITH SMALLER BATCH SIZE

6/02/2022

Continue conformer block on ubuntu
also try resnet on GPU ubuntu

If nothing works, ill try pytorch in future, need to learn pytorch first

TO DO: MAKE CONFORMER IMPLEMENTATION
SOURCES:
Conformer: Convolution-augmented Transformer for Speech Recognition
Attention is all you need (for the transformer)
https://dcase.community/documents/challenge2021/technical_reports/DCASE2021_Ko_127_t3.pdf
https://dcase.community/documents/challenge2021/technical_reports/DCASE2021_Huang_24_t3.pdf
https://dcase.community/documents/challenge2021/technical_reports/DCASE2021_Zhang_67_t3.pd

8/3/2022
Tensorflow addons for MultiHeadAttention
https://github.com/tensorflow/addons/tree/v0.15.0

9/3/2022
Encoder->Embeddings->Attention->Decoder
Encoder: One-hot of 12 bits, for 12 classes

Data augmentation:https://github.com/thomeou/SALSA/blob/master/utilities/transforms.py
TO DO:
check positional encoding->how it is embedded in MHSA Module
try and run

18/3/2022
going with Zhang

keep in mind:::: downloaded cudnn 10.0, 7.65 might try to replace previous cudnn NOT YET!!!!!!
trying to run test on conformer, dimensions and subsampling layer idea based on Zhang

RWTAW PPOTAMIANO GIA TO EXTRACTION (MEL BANDS, FFT .... NUMBER OF BINS?? )

19/3/2022
PRENORM in FFN
The original Transformer uses post-norm residual units
(POSTNORM), where layer normalization occurs
after the sublayer and residual addition. However,
Chen et al. (2018) found that pre-norm residual
units (PRENORM), where layer normalization occurs immediately before the sublayer,
https://arxiv.org/pdf/1910.05895.pdf
https://github.com/tnq177/transformers_without_tears/tree/25026061979916afb193274438f7097945acf9bc

GLU: https://github.com/pytorch/pytorch/blob/96aaa311c0251d24decb9dc5da4957b7c590af6f/torch/nn/modules/activation.py#L551

installed tensorflow 2.0
CHECK LAYER NORMALIZATION, ONLY EXISTS IN TF.KERAS. 
FOUND THIS FOR KERAS: https://github.com/CyberZHG/keras-layer-normalization
CHANGED import tensorflow.keras backend to just keras backend in the layer-normalization.py code from the above  github

FOR CONV MODULE in CONFORMER:
To study the effect of kernel sizes in the depthwise convolution, we sweep the kernel size in {3, 7, 17, 32, 65} of the large
model, using the same kernel size for all layers. We find that the
performance improves with larger kernel sizes till kernel sizes
17 and 32. 32 IS BEST PERFORMING(file:///C:/Users/pouli/Documents/Mathimata/Eidiko_Thema/INFO/online_material/conformer_speech_recognition.pdf)
ALSO to this:
Zhang used 31 size kernel for their depthwise convolution

debugging mhsa :P

21/3/2022

Debugging

TODO: Read transformers xl, on bus
Read more on dimensions

DATA AUGM:https://github.com/thomeou/SALSA/blob/90562a236117f4810a4a821b6ae165d1255650eb/utilities/transforms.py

 Datagen_mode: dev, nb_files: 400, nb_classes:12
        nb_frames_file: 3000, feat_len: 64, nb_ch: 10, label_len:48

        Dataset: mic, split: [1, 2, 3, 4]
        batch_size: 128, feat_seq_len: 300, label_seq_len: 60, shuffle: True
        Total batches in dataset: 31
	Data in (128 (batch_size), 10 (nb_channels), 300 (seq_len), 64 (feat_len))

d_model: number of feature maps

SCALED ATTENTION CHECK DIMENSIONS 

22/3/2022

pre-processing: ypodeigmatolipsia: meiwsh syxnwthtas
				Hamming window size
				
pos encoding has 3 dimensions in https://github.com/lucidrains/conformer/blob/0e91f0323089cc00fbde3e112a984d94d0af09b8/conformer/conformer.py#L10
but mine has 4
https://github.com/sooftware/conformer/blob/9318418cef5b516cd094c0ce2a06b80309938c70/conformer/attention.py has 3 too
but changes it to 4 through dense layer, before multiplying q*pos_emb (likewise mine)

CHANGED base_layer.py line 597 from ._kera_shape to .shape
DOWNLOADED TENSORFLOW 2.2.0
CHANGED https://stackoverflow.com/questions/60581677/experimental-list-devices-attribute-missing-in-tensorflow-core-api-v2-config
devices = tf.config.list_logical_devices()

_LOCAL_DEVICES = [x.name for x in devices]

DOWNLOADED TENSORFLOW 2.3.0
CHANGED https://github.com/tensorflow/tensorflow/issues/38589 
from tensorflow.python.framework import tensor_util
def is_tensor(x):                                                                                                                                                      
    return tensor_util.is_tensor(x)
	
DOWNLOADE TENSORFLOW 2.0.0
I cant take these conflicts anymore..... cant even code where is the fun

if cannot work until friday, i move on with data augmentation->pitch shift
(des kai diplwmatikh 2019 exei gia pitch shift)

tuple has no attribute _keras_shape::::
TURNED ALL MultiHeadAttention LAYERS TO FUNCTIONS

TO DO : -look into convmodule
		-data augmentation start sth
		
23/3/2022

Look into Ko's github: https://github.com/IRIS-AUDIO/SELD/blob/669ead73ce1e0db7bafef96d9f4037f9cf2cd0b7/modules.py#L1
https://github.com/TensorSpeech/TensorFlowASR/blob/main/tensorflow_asr/models/encoders/conformer.py
	
	# GLU Part
        conv_1, conv_2 = tf.split(conv, 2, axis=-1)
        conv_2 = tf.keras.activations.sigmoid(conv_2)
        conv = conv_1 * conv_2
		
INSTALLED TENSORFLOW 2.3.0 TO RUN DEPTHWISECONV2D LAYER

input output dimensions of conformer same(?)
will use permute and reshappe to make it into (60,512)

 Keras 2.3.1, which supports TensorFlow 2.x and 1.x, and is the latest real releases of Keras. You can also install Keras 2.2.4 which only supports TensorFlow 1.x.
 (https://stackoverflow.com/questions/62690377/tensorflow-compatibility-with-keras)
 
Tensorflow 2.3.0 gives another error i cannot solve
downgraded to 2.2.0
if i have to change version one more time i kill myself

When all versions fail try to uninstall cleanly
!pip uninstall keras -y
!pip uninstall keras-nightly -y
!pip uninstall keras-Preprocessing -y
!pip uninstall keras-vis -y
!pip uninstall tensorflow -y
(https://github.com/fizyr/keras-retinanet/issues/1538)

ON convolutions (depthwise, pointwise in pytorch though): https://github.com/sooftware/conformer/blob/9318418cef5b516cd094c0ce2a06b80309938c70/conformer/convolution.py#L24
CHECK KO'S GITHUB->his conformer input shape (batch, time, feat), but mine (influenced by Zhang) is (None, 256, 60, 2)=(batch, time, ??)
might revisit this in future, now next in list (if conformer works):
	TO DO:: Data augmentation technique
			--later, look into doa
			and try and implement idea of 3 overlapping sounds (where i run the input in 3 different frequencies)

			SUBSTITUTE Bi-GRU, no need just keep the conformers x2 (Zhang)

DEGRADED TO TENSORFLOW 1.15.0 BECAUSE MODEL COULD NOT RUN, tensorflow.python.framework.errors_impl.FailedPreconditionError:  Error while reading resource variable _AnonymousVar50 from Container: localhost. This could mean that the variable was uninitialized. Not found: Resource localhost/_AnonymousVar50/class tensorflow::Var does not exist.
         [[node conformer_1/layer_normalization_5/mul/ReadVariableOp (defined at C:\Users\pouli\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow_core\python\framework\ops.py:1751) ]] [Op:__inference_keras_scratch_graph_13788]

Function call stack:
keras_scratch_graph

mAYBE STH TO DO WITH k.SET_SESSION IN KERAS_MODELS???? NOooooo.... ITS THE CONFORMER
Turned Conformer class into function 

ALSO:
CHECK RESNETS, why last dense layer is 12???
!!!!!!!!!!! for resnet-34 last dense layer (512, 12, 12) NOT WORKING while resnet18 (256, 60, 12)
FIXED: resnet34 runs with 64 batch size (or lower) only!

K.set_session(session) in comments, tensorflow 2.x does not use it

LOAD ALREADY TRAINED MODELS: 
	from tensorflow.python.keras.models import load_model
	model = load_model(self.filename)
	
	Where self.filename is the name of the .h5 file in folder models (i believe)
	
UPGRADED TensorFlow 2.0.0

Added::
physical_devices = tf.config.experimental.list_physical_devices('GPU')
for device in physical_devices:
    tf.config.experimental.set_memory_growth(device, True)
	
on seld.py because gpu memory error again

TO DO::		-run on UBUNTU GPU to check if it still runs out of memory
			-Data augmentation technique->SpecAugment??Pitch shift
			-SUBSTITUTE Bi-GRU, no need just keep the conformers x2 (Zhang)
			--later, look into doa
			and try and implement idea of 3 overlapping sounds (where i run the input in 3 different frequencies)		
			-PLAY WITH PARAMETERS!!! (batch_size(already seen), frequency, window length)
	
24/3/2022

According to https://www.tensorflow.org/install/source?fbclid=IwAR0VECKFjEc6stp8rYYNjlV24usNzAr-kOSbDVblmsxqn4IKn6pNzrUUoMk#tensorflow_1x
i have cuda 11.0 so i need cudnn 8.0
Downloaded cudnn 8.0 and updated tensorflow 2.4.0

downgraded to tensorflow 2.0.0, 2.4.0 gives _Tensorlike error

Trying to modify all tf.[..] functions from models.py into keras layers
to be able to run conformer without the Resource localhost/_AnonymousVar50/class tensorflow::Var does not exist. Error

Put all tf.config gpu in comments in keras_models
UNDONE: put all print(spec_cnn) in comments in models.py and keras_models.py, cause not recognized by tensorflow version 2.4.0 but can be printed now that i have 2.0.0

TODO::::::: UBUNTUUUU, pitch shift data augm, new report, also try and use is_accdoa==false
LOOK INTO sel.py AND TRY TO UNDERSTAND HOW IT WORKS!!!!!!! ->>>>>>>>ASAPPPPPP, need for implementing a data augm technique
DOING:::::: Trying to debug conformer , getting error Resource localhost/_AnonymousVar50/class tensorflow::Var does not exist. Error

MUST SEE::(for sed and doa discrimination) https://github.com/thomeou/SALSA/blob/master/models/decoders.py
Also in the above git, she uses utilities to write experiment results in a folder-->>>>> i can use that
ALSO check the online_material folder and read 

TODO later(elafri diavasmataki):Shimadas paper  EINV2-based EINV2-D3Net approaches my idea of using 3 different outputs for the 3 overlapping sounds->>> check it out


model.fit_generator (seld.py)->>rtains the model, is the one that prints Epoch ?/5

OOM when allocating tensor with shape[7864320,512] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu
         [[{{node conformer_1/dense_5/MatMul}}]]
		 maybe matmul problem->>>try and replace it with k.backend
		 
		 
25/3/2022

Ubuntu did not work
probably need to replace tf.matmul cause thats where it always crashes
Also need to fix gpu recognition->>download other cudnn versions

Now need to look into data manipulation to understand how to implement data augm

hop_len parameter has effect on the hamming window length->> can tinker

feature_label_resolution = int(params['label_hop_len_s'] // params['hop_len_s'])
params['feature_sequence_length'] = params['label_sequence_length'] * feature_label_resolution
feature_sequence_length=600

feat is data_in and labels is data_out(what we try to predict):
feat_shape = (self._batch_size, self._nb_ch, self._feature_seq_len, self._nb_mel_bins)
label_shape = (self._batch_size, self._label_seq_len, self._nb_classes*3)

Maybe i need to modify the cs_data_generator.py to add data augmentation methods

what is a generator (needed in fit_generator to train model):https://stackoverflow.com/questions/231767/what-does-the-yield-keyword-do

FOR DATA AUGM::
https://github.com/TensorSpeech/TensorFlowASR/tree/caee2e79d0eb9d1a997f5df8e2ba3ee7f0a1bcae/tensorflow_asr/augmentations
https://github.com/thomeou/SALSA/blob/master/utilities/transforms.py